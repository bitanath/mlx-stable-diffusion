#TODO: Store all LORA layer mappings here in order to merge directly into model

simplified_clip_lora_mapping = {
  'layers.0.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_up.weight',
  'lora_te_text_model_encoder_layers_0_self_attn_out_proj.lora_down.weight'],
  'layers.0.linear_1.weight': ['lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_down.weight'],
  'layers.0.linear_2.weight': ['lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_down.weight'],
  'layers.1.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_1_self_attn_out_proj.lora_down.weight'],
  'layers.1.linear_1.weight': ['lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_1_mlp_fc1.lora_down.weight'],
  'layers.1.linear_2.weight': ['lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_1_mlp_fc2.lora_down.weight'],
  'layers.2.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_2_self_attn_out_proj.lora_down.weight'],
  'layers.2.linear_1.weight': ['lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_2_mlp_fc1.lora_down.weight'],
  'layers.2.linear_2.weight': ['lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_2_mlp_fc2.lora_down.weight'],
  'layers.3.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_3_self_attn_out_proj.lora_down.weight'],
  'layers.3.linear_1.weight': ['lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_3_mlp_fc1.lora_down.weight'],
  'layers.3.linear_2.weight': ['lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_3_mlp_fc2.lora_down.weight'],
  'layers.4.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_4_self_attn_out_proj.lora_down.weight'],
  'layers.4.linear_1.weight': ['lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_4_mlp_fc1.lora_down.weight'],
  'layers.4.linear_2.weight': ['lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_4_mlp_fc2.lora_down.weight'],
  'layers.5.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_5_self_attn_out_proj.lora_down.weight'],
  'layers.5.linear_1.weight': ['lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_5_mlp_fc1.lora_down.weight'],
  'layers.5.linear_2.weight': ['lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_5_mlp_fc2.lora_down.weight'],
  'layers.6.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_6_self_attn_out_proj.lora_down.weight'],
  'layers.6.linear_1.weight': ['lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_6_mlp_fc1.lora_down.weight'],
  'layers.6.linear_2.weight': ['lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_6_mlp_fc2.lora_down.weight'],
  'layers.7.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_7_self_attn_out_proj.lora_down.weight'],
  'layers.7.linear_1.weight': ['lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_7_mlp_fc1.lora_down.weight'],
  'layers.7.linear_2.weight': ['lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_7_mlp_fc2.lora_down.weight'],
  'layers.8.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_8_self_attn_out_proj.lora_down.weight'],
  'layers.8.linear_1.weight': ['lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_8_mlp_fc1.lora_down.weight'],
  'layers.8.linear_2.weight': ['lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_8_mlp_fc2.lora_down.weight'],
  'layers.9.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_9_self_attn_out_proj.lora_down.weight'],
  'layers.9.linear_1.weight': ['lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_9_mlp_fc1.lora_down.weight'],
  'layers.9.linear_2.weight': ['lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_9_mlp_fc2.lora_down.weight'],
  'layers.10.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_10_self_attn_out_proj.lora_down.weight'],
  'layers.10.linear_1.weight': ['lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_down.weight'],
  'layers.10.linear_2.weight': ['lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_10_mlp_fc2.lora_down.weight'],
  'layers.11.attention.out_proj.weight': ['lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_up.weight',
   'lora_te_text_model_encoder_layers_11_self_attn_out_proj.lora_down.weight'],
  'layers.11.linear_1.weight': ['lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up.weight',
   'lora_te_text_model_encoder_layers_11_mlp_fc1.lora_down.weight'],
  'layers.11.linear_2.weight': ['lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up.weight',
   'lora_te_text_model_encoder_layers_11_mlp_fc2.lora_down.weight'],
  '[layers.0.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_0_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_0_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_0_self_attn_v_proj.lora_down.weight']],
  '[layers.1.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_1_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_1_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_1_self_attn_v_proj.lora_down.weight']],
  '[layers.2.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_2_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_2_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_2_self_attn_v_proj.lora_down.weight']],
  '[layers.3.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_3_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_3_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_3_self_attn_v_proj.lora_down.weight']],
  '[layers.4.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_4_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_4_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_4_self_attn_v_proj.lora_down.weight']],
  '[layers.5.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_5_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_5_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_5_self_attn_v_proj.lora_down.weight']],
  '[layers.6.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_6_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_6_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_6_self_attn_v_proj.lora_down.weight']],
  '[layers.7.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_7_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_7_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_7_self_attn_v_proj.lora_down.weight']],
  '[layers.8.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_8_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_8_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_8_self_attn_v_proj.lora_down.weight']],
  '[layers.9.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_9_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_9_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_9_self_attn_v_proj.lora_down.weight']],
  '[layers.10.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_10_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_10_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_10_self_attn_v_proj.lora_down.weight']],
  '[layers.11.attention.in_proj.weight]': [['lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_11_self_attn_q_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_11_self_attn_k_proj.lora_down.weight'],
   ['lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_up.weight',
    'lora_te_text_model_encoder_layers_11_self_attn_v_proj.lora_down.weight']]
}

simplified_unet_lora_mapping = {
 'unet.encoders.1.1.conv_input.weight': ['lora_unet_down_blocks_0_attentions_0_proj_in.lora_up.weight',
 'lora_unet_down_blocks_0_attentions_0_proj_in.lora_down.weight'],
 'unet.encoders.1.1.conv_output.weight': ['lora_unet_down_blocks_0_attentions_0_proj_out.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_proj_out.lora_down.weight'],
 '[unet.encoders.1.1.attention_1.in_proj.weight]': [['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.encoders.1.1.attention_1.out_proj.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.encoders.1.1.attention_2.k_proj.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.encoders.1.1.attention_2.out_proj.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.encoders.1.1.attention_2.q_proj.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.encoders.1.1.attention_2.v_proj.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.encoders.1.1.linear_geglu_1.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.encoders.1.1.linear_geglu_2.weight': ['lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.encoders.2.1.conv_input.weight': ['lora_unet_down_blocks_0_attentions_1_proj_in.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_proj_in.lora_down.weight'],
 'unet.encoders.2.1.conv_output.weight': ['lora_unet_down_blocks_0_attentions_1_proj_out.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_proj_out.lora_down.weight'],
 '[unet.encoders.2.1.attention_1.in_proj.weight]': [['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.encoders.2.1.attention_1.out_proj.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.encoders.2.1.attention_2.k_proj.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.encoders.2.1.attention_2.out_proj.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.encoders.2.1.attention_2.q_proj.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.encoders.2.1.attention_2.v_proj.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.encoders.2.1.linear_geglu_1.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.encoders.2.1.linear_geglu_2.weight': ['lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_down_blocks_0_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.encoders.4.1.conv_input.weight': ['lora_unet_down_blocks_1_attentions_0_proj_in.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_proj_in.lora_down.weight'],
 'unet.encoders.4.1.conv_output.weight': ['lora_unet_down_blocks_1_attentions_0_proj_out.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_proj_out.lora_down.weight'],
 '[unet.encoders.4.1.attention_1.in_proj.weight]': [['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.encoders.4.1.attention_1.out_proj.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.encoders.4.1.attention_2.k_proj.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.encoders.4.1.attention_2.out_proj.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.encoders.4.1.attention_2.q_proj.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.encoders.4.1.attention_2.v_proj.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.encoders.4.1.linear_geglu_1.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.encoders.4.1.linear_geglu_2.weight': ['lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.encoders.5.1.conv_input.weight': ['lora_unet_down_blocks_1_attentions_1_proj_in.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_proj_in.lora_down.weight'],
 'unet.encoders.5.1.conv_output.weight': ['lora_unet_down_blocks_1_attentions_1_proj_out.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_proj_out.lora_down.weight'],
 '[unet.encoders.5.1.attention_1.in_proj.weight]': [['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.encoders.5.1.attention_1.out_proj.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.encoders.5.1.attention_2.k_proj.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.encoders.5.1.attention_2.out_proj.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.encoders.5.1.attention_2.q_proj.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.encoders.5.1.attention_2.v_proj.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.encoders.5.1.linear_geglu_1.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.encoders.5.1.linear_geglu_2.weight': ['lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_down_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.encoders.7.1.conv_input.weight': ['lora_unet_down_blocks_2_attentions_0_proj_in.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_proj_in.lora_down.weight'],
 'unet.encoders.7.1.conv_output.weight': ['lora_unet_down_blocks_2_attentions_0_proj_out.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_proj_out.lora_down.weight'],
 '[unet.encoders.7.1.attention_1.in_proj.weight]': [['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.encoders.7.1.attention_1.out_proj.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.encoders.7.1.attention_2.k_proj.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.encoders.7.1.attention_2.out_proj.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.encoders.7.1.attention_2.q_proj.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.encoders.7.1.attention_2.v_proj.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.encoders.7.1.linear_geglu_1.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.encoders.7.1.linear_geglu_2.weight': ['lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.encoders.8.1.conv_input.weight': ['lora_unet_down_blocks_2_attentions_1_proj_in.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_proj_in.lora_down.weight'],
 'unet.encoders.8.1.conv_output.weight': ['lora_unet_down_blocks_2_attentions_1_proj_out.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_proj_out.lora_down.weight'],
 '[unet.encoders.8.1.attention_1.in_proj.weight]': [['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.encoders.8.1.attention_1.out_proj.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.encoders.8.1.attention_2.k_proj.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.encoders.8.1.attention_2.out_proj.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.encoders.8.1.attention_2.q_proj.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.encoders.8.1.attention_2.v_proj.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.encoders.8.1.linear_geglu_1.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.encoders.8.1.linear_geglu_2.weight': ['lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_down_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.bottleneck.1.conv_input.weight': ['lora_unet_mid_block_attentions_0_proj_in.lora_up.weight',
  'lora_unet_mid_block_attentions_0_proj_in.lora_down.weight'],
 'unet.bottleneck.1.conv_output.weight': ['lora_unet_mid_block_attentions_0_proj_out.lora_up.weight',
  'lora_unet_mid_block_attentions_0_proj_out.lora_down.weight'],
 '[unet.bottleneck.1.attention_1.in_proj.weight]': [['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.bottleneck.1.attention_1.out_proj.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.bottleneck.1.attention_2.k_proj.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.bottleneck.1.attention_2.out_proj.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.bottleneck.1.attention_2.q_proj.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.bottleneck.1.attention_2.v_proj.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.bottleneck.1.linear_geglu_1.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.bottleneck.1.linear_geglu_2.weight': ['lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_mid_block_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.3.1.conv_input.weight': ['lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_proj_in.lora_down.weight'],
 'unet.decoders.3.1.conv_output.weight': ['lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_proj_out.lora_down.weight'],
 '[unet.decoders.3.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.3.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.3.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.3.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.3.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.3.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.3.1.linear_geglu_1.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.3.1.linear_geglu_2.weight': ['lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.4.1.conv_input.weight': ['lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_proj_in.lora_down.weight'],
 'unet.decoders.4.1.conv_output.weight': ['lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_proj_out.lora_down.weight'],
 '[unet.decoders.4.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.4.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.4.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.4.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.4.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.4.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.4.1.linear_geglu_1.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.4.1.linear_geglu_2.weight': ['lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.5.1.conv_input.weight': ['lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_proj_in.lora_down.weight'],
 'unet.decoders.5.1.conv_output.weight': ['lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_proj_out.lora_down.weight'],
 '[unet.decoders.5.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.5.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.5.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.5.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.5.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.5.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.5.1.linear_geglu_1.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.5.1.linear_geglu_2.weight': ['lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_1_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.6.1.conv_input.weight': ['lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_proj_in.lora_down.weight'],
 'unet.decoders.6.1.conv_output.weight': ['lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_proj_out.lora_down.weight'],
 '[unet.decoders.6.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.6.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.6.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.6.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.6.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.6.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.6.1.linear_geglu_1.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.6.1.linear_geglu_2.weight': ['lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.7.1.conv_input.weight': ['lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_proj_in.lora_down.weight'],
 'unet.decoders.7.1.conv_output.weight': ['lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_proj_out.lora_down.weight'],
 '[unet.decoders.7.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.7.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.7.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.7.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.7.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.7.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.7.1.linear_geglu_1.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.7.1.linear_geglu_2.weight': ['lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.8.1.conv_input.weight': ['lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_proj_in.lora_down.weight'],
 'unet.decoders.8.1.conv_output.weight': ['lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_proj_out.lora_down.weight'],
 '[unet.decoders.8.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.8.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.8.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.8.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.8.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.8.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.8.1.linear_geglu_1.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.8.1.linear_geglu_2.weight': ['lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_2_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.9.1.conv_input.weight': ['lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_proj_in.lora_down.weight'],
 'unet.decoders.9.1.conv_output.weight': ['lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_proj_out.lora_down.weight'],
 '[unet.decoders.9.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.9.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.9.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.9.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.9.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.9.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.9.1.linear_geglu_1.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.9.1.linear_geglu_2.weight': ['lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_0_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.10.1.conv_input.weight': ['lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_proj_in.lora_down.weight'],
 'unet.decoders.10.1.conv_output.weight': ['lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_proj_out.lora_down.weight'],
 '[unet.decoders.10.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.10.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.10.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.10.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.10.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.10.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.10.1.linear_geglu_1.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.10.1.linear_geglu_2.weight': ['lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_1_transformer_blocks_0_ff_net_2.lora_down.weight'],
 'unet.decoders.11.1.conv_input.weight': ['lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_proj_in.lora_down.weight'],
 'unet.decoders.11.1.conv_output.weight': ['lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_proj_out.lora_down.weight'],
 '[unet.decoders.11.1.attention_1.in_proj.weight]': [['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_k.lora_down.weight'],
  ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_q.lora_down.weight'],
  ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_up.weight',
   'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_v.lora_down.weight']],
 'unet.decoders.11.1.attention_1.out_proj.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn1_to_out_0.lora_down.weight'],
 'unet.decoders.11.1.attention_2.k_proj.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_k.lora_down.weight'],
 'unet.decoders.11.1.attention_2.out_proj.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_out_0.lora_down.weight'],
 'unet.decoders.11.1.attention_2.q_proj.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_q.lora_down.weight'],
 'unet.decoders.11.1.attention_2.v_proj.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_attn2_to_v.lora_down.weight'],
 'unet.decoders.11.1.linear_geglu_1.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_0_proj.lora_down.weight'],
 'unet.decoders.11.1.linear_geglu_2.weight': ['lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_up.weight',
  'lora_unet_up_blocks_3_attentions_2_transformer_blocks_0_ff_net_2.lora_down.weight']
}

diffusion_model_keys = [
'time_embedding.linear_1.weight',
'time_embedding.linear_1.bias',
'time_embedding.linear_2.weight',
'time_embedding.linear_2.bias',
'unet.encoders.0.layers.0.weight',
'unet.encoders.0.layers.0.bias',
'unet.encoders.1.layers.0.groupnorm_feature.weight',
'unet.encoders.1.layers.0.groupnorm_feature.bias',
'unet.encoders.1.layers.0.conv_feature.weight',
'unet.encoders.1.layers.0.conv_feature.bias',
'unet.encoders.1.layers.0.linear_time.weight',
'unet.encoders.1.layers.0.linear_time.bias',
'unet.encoders.1.layers.0.groupnorm_merged.weight',
'unet.encoders.1.layers.0.groupnorm_merged.bias',
'unet.encoders.1.layers.0.conv_merged.weight',
'unet.encoders.1.layers.0.conv_merged.bias',
'unet.encoders.1.layers.1.groupnorm.weight',
'unet.encoders.1.layers.1.groupnorm.bias',
'unet.encoders.1.layers.1.conv_input.weight',
'unet.encoders.1.layers.1.conv_input.bias',
'unet.encoders.1.layers.1.attention_1.out_proj.weight',
'unet.encoders.1.layers.1.attention_1.out_proj.bias',
'unet.encoders.1.layers.1.linear_geglu_1.weight',
'unet.encoders.1.layers.1.linear_geglu_1.bias',
'unet.encoders.1.layers.1.linear_geglu_2.weight',
'unet.encoders.1.layers.1.linear_geglu_2.bias',
'unet.encoders.1.layers.1.attention_2.q_proj.weight',
'unet.encoders.1.layers.1.attention_2.k_proj.weight',
'unet.encoders.1.layers.1.attention_2.v_proj.weight',
'unet.encoders.1.layers.1.attention_2.out_proj.weight',
'unet.encoders.1.layers.1.attention_2.out_proj.bias',
'unet.encoders.1.layers.1.layernorm_1.weight',
'unet.encoders.1.layers.1.layernorm_1.bias',
'unet.encoders.1.layers.1.layernorm_2.weight',
'unet.encoders.1.layers.1.layernorm_2.bias',
'unet.encoders.1.layers.1.layernorm_3.weight',
'unet.encoders.1.layers.1.layernorm_3.bias',
'unet.encoders.1.layers.1.conv_output.weight',
'unet.encoders.1.layers.1.conv_output.bias',
'unet.encoders.2.layers.0.groupnorm_feature.weight',
'unet.encoders.2.layers.0.groupnorm_feature.bias',
'unet.encoders.2.layers.0.conv_feature.weight',
'unet.encoders.2.layers.0.conv_feature.bias',
'unet.encoders.2.layers.0.linear_time.weight',
'unet.encoders.2.layers.0.linear_time.bias',
'unet.encoders.2.layers.0.groupnorm_merged.weight',
'unet.encoders.2.layers.0.groupnorm_merged.bias',
'unet.encoders.2.layers.0.conv_merged.weight',
'unet.encoders.2.layers.0.conv_merged.bias',
'unet.encoders.2.layers.1.groupnorm.weight',
'unet.encoders.2.layers.1.groupnorm.bias',
'unet.encoders.2.layers.1.conv_input.weight',
'unet.encoders.2.layers.1.conv_input.bias',
'unet.encoders.2.layers.1.attention_1.out_proj.weight',
'unet.encoders.2.layers.1.attention_1.out_proj.bias',
'unet.encoders.2.layers.1.linear_geglu_1.weight',
'unet.encoders.2.layers.1.linear_geglu_1.bias',
'unet.encoders.2.layers.1.linear_geglu_2.weight',
'unet.encoders.2.layers.1.linear_geglu_2.bias',
'unet.encoders.2.layers.1.attention_2.q_proj.weight',
'unet.encoders.2.layers.1.attention_2.k_proj.weight',
'unet.encoders.2.layers.1.attention_2.v_proj.weight',
'unet.encoders.2.layers.1.attention_2.out_proj.weight',
'unet.encoders.2.layers.1.attention_2.out_proj.bias',
'unet.encoders.2.layers.1.layernorm_1.weight',
'unet.encoders.2.layers.1.layernorm_1.bias',
'unet.encoders.2.layers.1.layernorm_2.weight',
'unet.encoders.2.layers.1.layernorm_2.bias',
'unet.encoders.2.layers.1.layernorm_3.weight',
'unet.encoders.2.layers.1.layernorm_3.bias',
'unet.encoders.2.layers.1.conv_output.weight',
'unet.encoders.2.layers.1.conv_output.bias',
'unet.encoders.3.layers.0.weight',
'unet.encoders.3.layers.0.bias',
'unet.encoders.4.layers.0.groupnorm_feature.weight',
'unet.encoders.4.layers.0.groupnorm_feature.bias',
'unet.encoders.4.layers.0.conv_feature.weight',
'unet.encoders.4.layers.0.conv_feature.bias',
'unet.encoders.4.layers.0.linear_time.weight',
'unet.encoders.4.layers.0.linear_time.bias',
'unet.encoders.4.layers.0.groupnorm_merged.weight',
'unet.encoders.4.layers.0.groupnorm_merged.bias',
'unet.encoders.4.layers.0.conv_merged.weight',
'unet.encoders.4.layers.0.conv_merged.bias',
'unet.encoders.4.layers.0.residual_layer.weight',
'unet.encoders.4.layers.0.residual_layer.bias',
'unet.encoders.4.layers.1.groupnorm.weight',
'unet.encoders.4.layers.1.groupnorm.bias',
'unet.encoders.4.layers.1.conv_input.weight',
'unet.encoders.4.layers.1.conv_input.bias',
'unet.encoders.4.layers.1.attention_1.out_proj.weight',
'unet.encoders.4.layers.1.attention_1.out_proj.bias',
'unet.encoders.4.layers.1.linear_geglu_1.weight',
'unet.encoders.4.layers.1.linear_geglu_1.bias',
'unet.encoders.4.layers.1.linear_geglu_2.weight',
'unet.encoders.4.layers.1.linear_geglu_2.bias',
'unet.encoders.4.layers.1.attention_2.q_proj.weight',
'unet.encoders.4.layers.1.attention_2.k_proj.weight',
'unet.encoders.4.layers.1.attention_2.v_proj.weight',
'unet.encoders.4.layers.1.attention_2.out_proj.weight',
'unet.encoders.4.layers.1.attention_2.out_proj.bias',
'unet.encoders.4.layers.1.layernorm_1.weight',
'unet.encoders.4.layers.1.layernorm_1.bias',
'unet.encoders.4.layers.1.layernorm_2.weight',
'unet.encoders.4.layers.1.layernorm_2.bias',
'unet.encoders.4.layers.1.layernorm_3.weight',
'unet.encoders.4.layers.1.layernorm_3.bias',
'unet.encoders.4.layers.1.conv_output.weight',
'unet.encoders.4.layers.1.conv_output.bias',
'unet.encoders.5.layers.0.groupnorm_feature.weight',
'unet.encoders.5.layers.0.groupnorm_feature.bias',
'unet.encoders.5.layers.0.conv_feature.weight',
'unet.encoders.5.layers.0.conv_feature.bias',
'unet.encoders.5.layers.0.linear_time.weight',
'unet.encoders.5.layers.0.linear_time.bias',
'unet.encoders.5.layers.0.groupnorm_merged.weight',
'unet.encoders.5.layers.0.groupnorm_merged.bias',
'unet.encoders.5.layers.0.conv_merged.weight',
'unet.encoders.5.layers.0.conv_merged.bias',
'unet.encoders.5.layers.1.groupnorm.weight',
'unet.encoders.5.layers.1.groupnorm.bias',
'unet.encoders.5.layers.1.conv_input.weight',
'unet.encoders.5.layers.1.conv_input.bias',
'unet.encoders.5.layers.1.attention_1.out_proj.weight',
'unet.encoders.5.layers.1.attention_1.out_proj.bias',
'unet.encoders.5.layers.1.linear_geglu_1.weight',
'unet.encoders.5.layers.1.linear_geglu_1.bias',
'unet.encoders.5.layers.1.linear_geglu_2.weight',
'unet.encoders.5.layers.1.linear_geglu_2.bias',
'unet.encoders.5.layers.1.attention_2.q_proj.weight',
'unet.encoders.5.layers.1.attention_2.k_proj.weight',
'unet.encoders.5.layers.1.attention_2.v_proj.weight',
'unet.encoders.5.layers.1.attention_2.out_proj.weight',
'unet.encoders.5.layers.1.attention_2.out_proj.bias',
'unet.encoders.5.layers.1.layernorm_1.weight',
'unet.encoders.5.layers.1.layernorm_1.bias',
'unet.encoders.5.layers.1.layernorm_2.weight',
'unet.encoders.5.layers.1.layernorm_2.bias',
'unet.encoders.5.layers.1.layernorm_3.weight',
'unet.encoders.5.layers.1.layernorm_3.bias',
'unet.encoders.5.layers.1.conv_output.weight',
'unet.encoders.5.layers.1.conv_output.bias',
'unet.encoders.6.layers.0.weight',
'unet.encoders.6.layers.0.bias',
'unet.encoders.7.layers.0.groupnorm_feature.weight',
'unet.encoders.7.layers.0.groupnorm_feature.bias',
'unet.encoders.7.layers.0.conv_feature.weight',
'unet.encoders.7.layers.0.conv_feature.bias',
'unet.encoders.7.layers.0.linear_time.weight',
'unet.encoders.7.layers.0.linear_time.bias',
'unet.encoders.7.layers.0.groupnorm_merged.weight',
'unet.encoders.7.layers.0.groupnorm_merged.bias',
'unet.encoders.7.layers.0.conv_merged.weight',
'unet.encoders.7.layers.0.conv_merged.bias',
'unet.encoders.7.layers.0.residual_layer.weight',
'unet.encoders.7.layers.0.residual_layer.bias',
'unet.encoders.7.layers.1.groupnorm.weight',
'unet.encoders.7.layers.1.groupnorm.bias',
'unet.encoders.7.layers.1.conv_input.weight',
'unet.encoders.7.layers.1.conv_input.bias',
'unet.encoders.7.layers.1.attention_1.out_proj.weight',
'unet.encoders.7.layers.1.attention_1.out_proj.bias',
'unet.encoders.7.layers.1.linear_geglu_1.weight',
'unet.encoders.7.layers.1.linear_geglu_1.bias',
'unet.encoders.7.layers.1.linear_geglu_2.weight',
'unet.encoders.7.layers.1.linear_geglu_2.bias',
'unet.encoders.7.layers.1.attention_2.q_proj.weight',
'unet.encoders.7.layers.1.attention_2.k_proj.weight',
'unet.encoders.7.layers.1.attention_2.v_proj.weight',
'unet.encoders.7.layers.1.attention_2.out_proj.weight',
'unet.encoders.7.layers.1.attention_2.out_proj.bias',
'unet.encoders.7.layers.1.layernorm_1.weight',
'unet.encoders.7.layers.1.layernorm_1.bias',
'unet.encoders.7.layers.1.layernorm_2.weight',
'unet.encoders.7.layers.1.layernorm_2.bias',
'unet.encoders.7.layers.1.layernorm_3.weight',
'unet.encoders.7.layers.1.layernorm_3.bias',
'unet.encoders.7.layers.1.conv_output.weight',
'unet.encoders.7.layers.1.conv_output.bias',
'unet.encoders.8.layers.0.groupnorm_feature.weight',
'unet.encoders.8.layers.0.groupnorm_feature.bias',
'unet.encoders.8.layers.0.conv_feature.weight',
'unet.encoders.8.layers.0.conv_feature.bias',
'unet.encoders.8.layers.0.linear_time.weight',
'unet.encoders.8.layers.0.linear_time.bias',
'unet.encoders.8.layers.0.groupnorm_merged.weight',
'unet.encoders.8.layers.0.groupnorm_merged.bias',
'unet.encoders.8.layers.0.conv_merged.weight',
'unet.encoders.8.layers.0.conv_merged.bias',
'unet.encoders.8.layers.1.groupnorm.weight',
'unet.encoders.8.layers.1.groupnorm.bias',
'unet.encoders.8.layers.1.conv_input.weight',
'unet.encoders.8.layers.1.conv_input.bias',
'unet.encoders.8.layers.1.attention_1.out_proj.weight',
'unet.encoders.8.layers.1.attention_1.out_proj.bias',
'unet.encoders.8.layers.1.linear_geglu_1.weight',
'unet.encoders.8.layers.1.linear_geglu_1.bias',
'unet.encoders.8.layers.1.linear_geglu_2.weight',
'unet.encoders.8.layers.1.linear_geglu_2.bias',
'unet.encoders.8.layers.1.attention_2.q_proj.weight',
'unet.encoders.8.layers.1.attention_2.k_proj.weight',
'unet.encoders.8.layers.1.attention_2.v_proj.weight',
'unet.encoders.8.layers.1.attention_2.out_proj.weight',
'unet.encoders.8.layers.1.attention_2.out_proj.bias',
'unet.encoders.8.layers.1.layernorm_1.weight',
'unet.encoders.8.layers.1.layernorm_1.bias',
'unet.encoders.8.layers.1.layernorm_2.weight',
'unet.encoders.8.layers.1.layernorm_2.bias',
'unet.encoders.8.layers.1.layernorm_3.weight',
'unet.encoders.8.layers.1.layernorm_3.bias',
'unet.encoders.8.layers.1.conv_output.weight',
'unet.encoders.8.layers.1.conv_output.bias',
'unet.encoders.9.layers.0.weight',
'unet.encoders.9.layers.0.bias',
'unet.encoders.10.layers.0.groupnorm_feature.weight',
'unet.encoders.10.layers.0.groupnorm_feature.bias',
'unet.encoders.10.layers.0.conv_feature.weight',
'unet.encoders.10.layers.0.conv_feature.bias',
'unet.encoders.10.layers.0.linear_time.weight',
'unet.encoders.10.layers.0.linear_time.bias',
'unet.encoders.10.layers.0.groupnorm_merged.weight',
'unet.encoders.10.layers.0.groupnorm_merged.bias',
'unet.encoders.10.layers.0.conv_merged.weight',
'unet.encoders.10.layers.0.conv_merged.bias',
'unet.encoders.11.layers.0.groupnorm_feature.weight',
'unet.encoders.11.layers.0.groupnorm_feature.bias',
'unet.encoders.11.layers.0.conv_feature.weight',
'unet.encoders.11.layers.0.conv_feature.bias',
'unet.encoders.11.layers.0.linear_time.weight',
'unet.encoders.11.layers.0.linear_time.bias',
'unet.encoders.11.layers.0.groupnorm_merged.weight',
'unet.encoders.11.layers.0.groupnorm_merged.bias',
'unet.encoders.11.layers.0.conv_merged.weight',
'unet.encoders.11.layers.0.conv_merged.bias',
'unet.bottleneck.layers.0.groupnorm_feature.weight',
'unet.bottleneck.layers.0.groupnorm_feature.bias',
'unet.bottleneck.layers.0.conv_feature.weight',
'unet.bottleneck.layers.0.conv_feature.bias',
'unet.bottleneck.layers.0.linear_time.weight',
'unet.bottleneck.layers.0.linear_time.bias',
'unet.bottleneck.layers.0.groupnorm_merged.weight',
'unet.bottleneck.layers.0.groupnorm_merged.bias',
'unet.bottleneck.layers.0.conv_merged.weight',
'unet.bottleneck.layers.0.conv_merged.bias',
'unet.bottleneck.layers.1.groupnorm.weight',
'unet.bottleneck.layers.1.groupnorm.bias',
'unet.bottleneck.layers.1.conv_input.weight',
'unet.bottleneck.layers.1.conv_input.bias',
'unet.bottleneck.layers.1.attention_1.out_proj.weight',
'unet.bottleneck.layers.1.attention_1.out_proj.bias',
'unet.bottleneck.layers.1.linear_geglu_1.weight',
'unet.bottleneck.layers.1.linear_geglu_1.bias',
'unet.bottleneck.layers.1.linear_geglu_2.weight',
'unet.bottleneck.layers.1.linear_geglu_2.bias',
'unet.bottleneck.layers.1.attention_2.q_proj.weight',
'unet.bottleneck.layers.1.attention_2.k_proj.weight',
'unet.bottleneck.layers.1.attention_2.v_proj.weight',
'unet.bottleneck.layers.1.attention_2.out_proj.weight',
'unet.bottleneck.layers.1.attention_2.out_proj.bias',
'unet.bottleneck.layers.1.layernorm_1.weight',
'unet.bottleneck.layers.1.layernorm_1.bias',
'unet.bottleneck.layers.1.layernorm_2.weight',
'unet.bottleneck.layers.1.layernorm_2.bias',
'unet.bottleneck.layers.1.layernorm_3.weight',
'unet.bottleneck.layers.1.layernorm_3.bias',
'unet.bottleneck.layers.1.conv_output.weight',
'unet.bottleneck.layers.1.conv_output.bias',
'unet.bottleneck.layers.2.groupnorm_feature.weight',
'unet.bottleneck.layers.2.groupnorm_feature.bias',
'unet.bottleneck.layers.2.conv_feature.weight',
'unet.bottleneck.layers.2.conv_feature.bias',
'unet.bottleneck.layers.2.linear_time.weight',
'unet.bottleneck.layers.2.linear_time.bias',
'unet.bottleneck.layers.2.groupnorm_merged.weight',
'unet.bottleneck.layers.2.groupnorm_merged.bias',
'unet.bottleneck.layers.2.conv_merged.weight',
'unet.bottleneck.layers.2.conv_merged.bias',
'unet.decoders.0.layers.0.groupnorm_feature.weight',
'unet.decoders.0.layers.0.groupnorm_feature.bias',
'unet.decoders.0.layers.0.conv_feature.weight',
'unet.decoders.0.layers.0.conv_feature.bias',
'unet.decoders.0.layers.0.linear_time.weight',
'unet.decoders.0.layers.0.linear_time.bias',
'unet.decoders.0.layers.0.groupnorm_merged.weight',
'unet.decoders.0.layers.0.groupnorm_merged.bias',
'unet.decoders.0.layers.0.conv_merged.weight',
'unet.decoders.0.layers.0.conv_merged.bias',
'unet.decoders.0.layers.0.residual_layer.weight',
'unet.decoders.0.layers.0.residual_layer.bias',
'unet.decoders.1.layers.0.groupnorm_feature.weight',
'unet.decoders.1.layers.0.groupnorm_feature.bias',
'unet.decoders.1.layers.0.conv_feature.weight',
'unet.decoders.1.layers.0.conv_feature.bias',
'unet.decoders.1.layers.0.linear_time.weight',
'unet.decoders.1.layers.0.linear_time.bias',
'unet.decoders.1.layers.0.groupnorm_merged.weight',
'unet.decoders.1.layers.0.groupnorm_merged.bias',
'unet.decoders.1.layers.0.conv_merged.weight',
'unet.decoders.1.layers.0.conv_merged.bias',
'unet.decoders.1.layers.0.residual_layer.weight',
'unet.decoders.1.layers.0.residual_layer.bias',
'unet.decoders.2.layers.0.groupnorm_feature.weight',
'unet.decoders.2.layers.0.groupnorm_feature.bias',
'unet.decoders.2.layers.0.conv_feature.weight',
'unet.decoders.2.layers.0.conv_feature.bias',
'unet.decoders.2.layers.0.linear_time.weight',
'unet.decoders.2.layers.0.linear_time.bias',
'unet.decoders.2.layers.0.groupnorm_merged.weight',
'unet.decoders.2.layers.0.groupnorm_merged.bias',
'unet.decoders.2.layers.0.conv_merged.weight',
'unet.decoders.2.layers.0.conv_merged.bias',
'unet.decoders.2.layers.0.residual_layer.weight',
'unet.decoders.2.layers.0.residual_layer.bias',
'unet.decoders.2.layers.1.conv.weight',
'unet.decoders.2.layers.1.conv.bias',
'unet.decoders.3.layers.0.groupnorm_feature.weight',
'unet.decoders.3.layers.0.groupnorm_feature.bias',
'unet.decoders.3.layers.0.conv_feature.weight',
'unet.decoders.3.layers.0.conv_feature.bias',
'unet.decoders.3.layers.0.linear_time.weight',
'unet.decoders.3.layers.0.linear_time.bias',
'unet.decoders.3.layers.0.groupnorm_merged.weight',
'unet.decoders.3.layers.0.groupnorm_merged.bias',
'unet.decoders.3.layers.0.conv_merged.weight',
'unet.decoders.3.layers.0.conv_merged.bias',
'unet.decoders.3.layers.0.residual_layer.weight',
'unet.decoders.3.layers.0.residual_layer.bias',
'unet.decoders.3.layers.1.groupnorm.weight',
'unet.decoders.3.layers.1.groupnorm.bias',
'unet.decoders.3.layers.1.conv_input.weight',
'unet.decoders.3.layers.1.conv_input.bias',
'unet.decoders.3.layers.1.attention_1.out_proj.weight',
'unet.decoders.3.layers.1.attention_1.out_proj.bias',
'unet.decoders.3.layers.1.linear_geglu_1.weight',
'unet.decoders.3.layers.1.linear_geglu_1.bias',
'unet.decoders.3.layers.1.linear_geglu_2.weight',
'unet.decoders.3.layers.1.linear_geglu_2.bias',
'unet.decoders.3.layers.1.attention_2.q_proj.weight',
'unet.decoders.3.layers.1.attention_2.k_proj.weight',
'unet.decoders.3.layers.1.attention_2.v_proj.weight',
'unet.decoders.3.layers.1.attention_2.out_proj.weight',
'unet.decoders.3.layers.1.attention_2.out_proj.bias',
'unet.decoders.3.layers.1.layernorm_1.weight',
'unet.decoders.3.layers.1.layernorm_1.bias',
'unet.decoders.3.layers.1.layernorm_2.weight',
'unet.decoders.3.layers.1.layernorm_2.bias',
'unet.decoders.3.layers.1.layernorm_3.weight',
'unet.decoders.3.layers.1.layernorm_3.bias',
'unet.decoders.3.layers.1.conv_output.weight',
'unet.decoders.3.layers.1.conv_output.bias',
'unet.decoders.4.layers.0.groupnorm_feature.weight',
'unet.decoders.4.layers.0.groupnorm_feature.bias',
'unet.decoders.4.layers.0.conv_feature.weight',
'unet.decoders.4.layers.0.conv_feature.bias',
'unet.decoders.4.layers.0.linear_time.weight',
'unet.decoders.4.layers.0.linear_time.bias',
'unet.decoders.4.layers.0.groupnorm_merged.weight',
'unet.decoders.4.layers.0.groupnorm_merged.bias',
'unet.decoders.4.layers.0.conv_merged.weight',
'unet.decoders.4.layers.0.conv_merged.bias',
'unet.decoders.4.layers.0.residual_layer.weight',
'unet.decoders.4.layers.0.residual_layer.bias',
'unet.decoders.4.layers.1.groupnorm.weight',
'unet.decoders.4.layers.1.groupnorm.bias',
'unet.decoders.4.layers.1.conv_input.weight',
'unet.decoders.4.layers.1.conv_input.bias',
'unet.decoders.4.layers.1.attention_1.out_proj.weight',
'unet.decoders.4.layers.1.attention_1.out_proj.bias',
'unet.decoders.4.layers.1.linear_geglu_1.weight',
'unet.decoders.4.layers.1.linear_geglu_1.bias',
'unet.decoders.4.layers.1.linear_geglu_2.weight',
'unet.decoders.4.layers.1.linear_geglu_2.bias',
'unet.decoders.4.layers.1.attention_2.q_proj.weight',
'unet.decoders.4.layers.1.attention_2.k_proj.weight',
'unet.decoders.4.layers.1.attention_2.v_proj.weight',
'unet.decoders.4.layers.1.attention_2.out_proj.weight',
'unet.decoders.4.layers.1.attention_2.out_proj.bias',
'unet.decoders.4.layers.1.layernorm_1.weight',
'unet.decoders.4.layers.1.layernorm_1.bias',
'unet.decoders.4.layers.1.layernorm_2.weight',
'unet.decoders.4.layers.1.layernorm_2.bias',
'unet.decoders.4.layers.1.layernorm_3.weight',
'unet.decoders.4.layers.1.layernorm_3.bias',
'unet.decoders.4.layers.1.conv_output.weight',
'unet.decoders.4.layers.1.conv_output.bias',
'unet.decoders.5.layers.0.groupnorm_feature.weight',
'unet.decoders.5.layers.0.groupnorm_feature.bias',
'unet.decoders.5.layers.0.conv_feature.weight',
'unet.decoders.5.layers.0.conv_feature.bias',
'unet.decoders.5.layers.0.linear_time.weight',
'unet.decoders.5.layers.0.linear_time.bias',
'unet.decoders.5.layers.0.groupnorm_merged.weight',
'unet.decoders.5.layers.0.groupnorm_merged.bias',
'unet.decoders.5.layers.0.conv_merged.weight',
'unet.decoders.5.layers.0.conv_merged.bias',
'unet.decoders.5.layers.0.residual_layer.weight',
'unet.decoders.5.layers.0.residual_layer.bias',
'unet.decoders.5.layers.1.groupnorm.weight',
'unet.decoders.5.layers.1.groupnorm.bias',
'unet.decoders.5.layers.1.conv_input.weight',
'unet.decoders.5.layers.1.conv_input.bias',
'unet.decoders.5.layers.1.attention_1.out_proj.weight',
'unet.decoders.5.layers.1.attention_1.out_proj.bias',
'unet.decoders.5.layers.1.linear_geglu_1.weight',
'unet.decoders.5.layers.1.linear_geglu_1.bias',
'unet.decoders.5.layers.1.linear_geglu_2.weight',
'unet.decoders.5.layers.1.linear_geglu_2.bias',
'unet.decoders.5.layers.1.attention_2.q_proj.weight',
'unet.decoders.5.layers.1.attention_2.k_proj.weight',
'unet.decoders.5.layers.1.attention_2.v_proj.weight',
'unet.decoders.5.layers.1.attention_2.out_proj.weight',
'unet.decoders.5.layers.1.attention_2.out_proj.bias',
'unet.decoders.5.layers.1.layernorm_1.weight',
'unet.decoders.5.layers.1.layernorm_1.bias',
'unet.decoders.5.layers.1.layernorm_2.weight',
'unet.decoders.5.layers.1.layernorm_2.bias',
'unet.decoders.5.layers.1.layernorm_3.weight',
'unet.decoders.5.layers.1.layernorm_3.bias',
'unet.decoders.5.layers.1.conv_output.weight',
'unet.decoders.5.layers.1.conv_output.bias',
'unet.decoders.5.layers.2.conv.weight',
'unet.decoders.5.layers.2.conv.bias',
'unet.decoders.6.layers.0.groupnorm_feature.weight',
'unet.decoders.6.layers.0.groupnorm_feature.bias',
'unet.decoders.6.layers.0.conv_feature.weight',
'unet.decoders.6.layers.0.conv_feature.bias',
'unet.decoders.6.layers.0.linear_time.weight',
'unet.decoders.6.layers.0.linear_time.bias',
'unet.decoders.6.layers.0.groupnorm_merged.weight',
'unet.decoders.6.layers.0.groupnorm_merged.bias',
'unet.decoders.6.layers.0.conv_merged.weight',
'unet.decoders.6.layers.0.conv_merged.bias',
'unet.decoders.6.layers.0.residual_layer.weight',
'unet.decoders.6.layers.0.residual_layer.bias',
'unet.decoders.6.layers.1.groupnorm.weight',
'unet.decoders.6.layers.1.groupnorm.bias',
'unet.decoders.6.layers.1.conv_input.weight',
'unet.decoders.6.layers.1.conv_input.bias',
'unet.decoders.6.layers.1.attention_1.out_proj.weight',
'unet.decoders.6.layers.1.attention_1.out_proj.bias',
'unet.decoders.6.layers.1.linear_geglu_1.weight',
'unet.decoders.6.layers.1.linear_geglu_1.bias',
'unet.decoders.6.layers.1.linear_geglu_2.weight',
'unet.decoders.6.layers.1.linear_geglu_2.bias',
'unet.decoders.6.layers.1.attention_2.q_proj.weight',
'unet.decoders.6.layers.1.attention_2.k_proj.weight',
'unet.decoders.6.layers.1.attention_2.v_proj.weight',
'unet.decoders.6.layers.1.attention_2.out_proj.weight',
'unet.decoders.6.layers.1.attention_2.out_proj.bias',
'unet.decoders.6.layers.1.layernorm_1.weight',
'unet.decoders.6.layers.1.layernorm_1.bias',
'unet.decoders.6.layers.1.layernorm_2.weight',
'unet.decoders.6.layers.1.layernorm_2.bias',
'unet.decoders.6.layers.1.layernorm_3.weight',
'unet.decoders.6.layers.1.layernorm_3.bias',
'unet.decoders.6.layers.1.conv_output.weight',
'unet.decoders.6.layers.1.conv_output.bias',
'unet.decoders.7.layers.0.groupnorm_feature.weight',
'unet.decoders.7.layers.0.groupnorm_feature.bias',
'unet.decoders.7.layers.0.conv_feature.weight',
'unet.decoders.7.layers.0.conv_feature.bias',
'unet.decoders.7.layers.0.linear_time.weight',
'unet.decoders.7.layers.0.linear_time.bias',
'unet.decoders.7.layers.0.groupnorm_merged.weight',
'unet.decoders.7.layers.0.groupnorm_merged.bias',
'unet.decoders.7.layers.0.conv_merged.weight',
'unet.decoders.7.layers.0.conv_merged.bias',
'unet.decoders.7.layers.0.residual_layer.weight',
'unet.decoders.7.layers.0.residual_layer.bias',
'unet.decoders.7.layers.1.groupnorm.weight',
'unet.decoders.7.layers.1.groupnorm.bias',
'unet.decoders.7.layers.1.conv_input.weight',
'unet.decoders.7.layers.1.conv_input.bias',
'unet.decoders.7.layers.1.attention_1.out_proj.weight',
'unet.decoders.7.layers.1.attention_1.out_proj.bias',
'unet.decoders.7.layers.1.linear_geglu_1.weight',
'unet.decoders.7.layers.1.linear_geglu_1.bias',
'unet.decoders.7.layers.1.linear_geglu_2.weight',
'unet.decoders.7.layers.1.linear_geglu_2.bias',
'unet.decoders.7.layers.1.attention_2.q_proj.weight',
'unet.decoders.7.layers.1.attention_2.k_proj.weight',
'unet.decoders.7.layers.1.attention_2.v_proj.weight',
'unet.decoders.7.layers.1.attention_2.out_proj.weight',
'unet.decoders.7.layers.1.attention_2.out_proj.bias',
'unet.decoders.7.layers.1.layernorm_1.weight',
'unet.decoders.7.layers.1.layernorm_1.bias',
'unet.decoders.7.layers.1.layernorm_2.weight',
'unet.decoders.7.layers.1.layernorm_2.bias',
'unet.decoders.7.layers.1.layernorm_3.weight',
'unet.decoders.7.layers.1.layernorm_3.bias',
'unet.decoders.7.layers.1.conv_output.weight',
'unet.decoders.7.layers.1.conv_output.bias',
'unet.decoders.8.layers.0.groupnorm_feature.weight',
'unet.decoders.8.layers.0.groupnorm_feature.bias',
'unet.decoders.8.layers.0.conv_feature.weight',
'unet.decoders.8.layers.0.conv_feature.bias',
'unet.decoders.8.layers.0.linear_time.weight',
'unet.decoders.8.layers.0.linear_time.bias',
'unet.decoders.8.layers.0.groupnorm_merged.weight',
'unet.decoders.8.layers.0.groupnorm_merged.bias',
'unet.decoders.8.layers.0.conv_merged.weight',
'unet.decoders.8.layers.0.conv_merged.bias',
'unet.decoders.8.layers.0.residual_layer.weight',
'unet.decoders.8.layers.0.residual_layer.bias',
'unet.decoders.8.layers.1.groupnorm.weight',
'unet.decoders.8.layers.1.groupnorm.bias',
'unet.decoders.8.layers.1.conv_input.weight',
'unet.decoders.8.layers.1.conv_input.bias',
'unet.decoders.8.layers.1.attention_1.out_proj.weight',
'unet.decoders.8.layers.1.attention_1.out_proj.bias',
'unet.decoders.8.layers.1.linear_geglu_1.weight',
'unet.decoders.8.layers.1.linear_geglu_1.bias',
'unet.decoders.8.layers.1.linear_geglu_2.weight',
'unet.decoders.8.layers.1.linear_geglu_2.bias',
'unet.decoders.8.layers.1.attention_2.q_proj.weight',
'unet.decoders.8.layers.1.attention_2.k_proj.weight',
'unet.decoders.8.layers.1.attention_2.v_proj.weight',
'unet.decoders.8.layers.1.attention_2.out_proj.weight',
'unet.decoders.8.layers.1.attention_2.out_proj.bias',
'unet.decoders.8.layers.1.layernorm_1.weight',
'unet.decoders.8.layers.1.layernorm_1.bias',
'unet.decoders.8.layers.1.layernorm_2.weight',
'unet.decoders.8.layers.1.layernorm_2.bias',
'unet.decoders.8.layers.1.layernorm_3.weight',
'unet.decoders.8.layers.1.layernorm_3.bias',
'unet.decoders.8.layers.1.conv_output.weight',
'unet.decoders.8.layers.1.conv_output.bias',
'unet.decoders.8.layers.2.conv.weight',
'unet.decoders.8.layers.2.conv.bias',
'unet.decoders.9.layers.0.groupnorm_feature.weight',
'unet.decoders.9.layers.0.groupnorm_feature.bias',
'unet.decoders.9.layers.0.conv_feature.weight',
'unet.decoders.9.layers.0.conv_feature.bias',
'unet.decoders.9.layers.0.linear_time.weight',
'unet.decoders.9.layers.0.linear_time.bias',
'unet.decoders.9.layers.0.groupnorm_merged.weight',
'unet.decoders.9.layers.0.groupnorm_merged.bias',
'unet.decoders.9.layers.0.conv_merged.weight',
'unet.decoders.9.layers.0.conv_merged.bias',
'unet.decoders.9.layers.0.residual_layer.weight',
'unet.decoders.9.layers.0.residual_layer.bias',
'unet.decoders.9.layers.1.groupnorm.weight',
'unet.decoders.9.layers.1.groupnorm.bias',
'unet.decoders.9.layers.1.conv_input.weight',
'unet.decoders.9.layers.1.conv_input.bias',
'unet.decoders.9.layers.1.attention_1.out_proj.weight',
'unet.decoders.9.layers.1.attention_1.out_proj.bias',
'unet.decoders.9.layers.1.linear_geglu_1.weight',
'unet.decoders.9.layers.1.linear_geglu_1.bias',
'unet.decoders.9.layers.1.linear_geglu_2.weight',
'unet.decoders.9.layers.1.linear_geglu_2.bias',
'unet.decoders.9.layers.1.attention_2.q_proj.weight',
'unet.decoders.9.layers.1.attention_2.k_proj.weight',
'unet.decoders.9.layers.1.attention_2.v_proj.weight',
'unet.decoders.9.layers.1.attention_2.out_proj.weight',
'unet.decoders.9.layers.1.attention_2.out_proj.bias',
'unet.decoders.9.layers.1.layernorm_1.weight',
'unet.decoders.9.layers.1.layernorm_1.bias',
'unet.decoders.9.layers.1.layernorm_2.weight',
'unet.decoders.9.layers.1.layernorm_2.bias',
'unet.decoders.9.layers.1.layernorm_3.weight',
'unet.decoders.9.layers.1.layernorm_3.bias',
'unet.decoders.9.layers.1.conv_output.weight',
'unet.decoders.9.layers.1.conv_output.bias',
'unet.decoders.10.layers.0.groupnorm_feature.weight',
'unet.decoders.10.layers.0.groupnorm_feature.bias',
'unet.decoders.10.layers.0.conv_feature.weight',
'unet.decoders.10.layers.0.conv_feature.bias',
'unet.decoders.10.layers.0.linear_time.weight',
'unet.decoders.10.layers.0.linear_time.bias',
'unet.decoders.10.layers.0.groupnorm_merged.weight',
'unet.decoders.10.layers.0.groupnorm_merged.bias',
'unet.decoders.10.layers.0.conv_merged.weight',
'unet.decoders.10.layers.0.conv_merged.bias',
'unet.decoders.10.layers.0.residual_layer.weight',
'unet.decoders.10.layers.0.residual_layer.bias',
'unet.decoders.10.layers.1.groupnorm.weight',
'unet.decoders.10.layers.1.groupnorm.bias',
'unet.decoders.10.layers.1.conv_input.weight',
'unet.decoders.10.layers.1.conv_input.bias',
'unet.decoders.10.layers.1.attention_1.out_proj.weight',
'unet.decoders.10.layers.1.attention_1.out_proj.bias',
'unet.decoders.10.layers.1.linear_geglu_1.weight',
'unet.decoders.10.layers.1.linear_geglu_1.bias',
'unet.decoders.10.layers.1.linear_geglu_2.weight',
'unet.decoders.10.layers.1.linear_geglu_2.bias',
'unet.decoders.10.layers.1.attention_2.q_proj.weight',
'unet.decoders.10.layers.1.attention_2.k_proj.weight',
'unet.decoders.10.layers.1.attention_2.v_proj.weight',
'unet.decoders.10.layers.1.attention_2.out_proj.weight',
'unet.decoders.10.layers.1.attention_2.out_proj.bias',
'unet.decoders.10.layers.1.layernorm_1.weight',
'unet.decoders.10.layers.1.layernorm_1.bias',
'unet.decoders.10.layers.1.layernorm_2.weight',
'unet.decoders.10.layers.1.layernorm_2.bias',
'unet.decoders.10.layers.1.layernorm_3.weight',
'unet.decoders.10.layers.1.layernorm_3.bias',
'unet.decoders.10.layers.1.conv_output.weight',
'unet.decoders.10.layers.1.conv_output.bias',
'unet.decoders.11.layers.0.groupnorm_feature.weight',
'unet.decoders.11.layers.0.groupnorm_feature.bias',
'unet.decoders.11.layers.0.conv_feature.weight',
'unet.decoders.11.layers.0.conv_feature.bias',
'unet.decoders.11.layers.0.linear_time.weight',
'unet.decoders.11.layers.0.linear_time.bias',
'unet.decoders.11.layers.0.groupnorm_merged.weight',
'unet.decoders.11.layers.0.groupnorm_merged.bias',
'unet.decoders.11.layers.0.conv_merged.weight',
'unet.decoders.11.layers.0.conv_merged.bias',
'unet.decoders.11.layers.0.residual_layer.weight',
'unet.decoders.11.layers.0.residual_layer.bias',
'unet.decoders.11.layers.1.groupnorm.weight',
'unet.decoders.11.layers.1.groupnorm.bias',
'unet.decoders.11.layers.1.conv_input.weight',
'unet.decoders.11.layers.1.conv_input.bias',
'unet.decoders.11.layers.1.attention_1.out_proj.weight',
'unet.decoders.11.layers.1.attention_1.out_proj.bias',
'unet.decoders.11.layers.1.linear_geglu_1.weight',
'unet.decoders.11.layers.1.linear_geglu_1.bias',
'unet.decoders.11.layers.1.linear_geglu_2.weight',
'unet.decoders.11.layers.1.linear_geglu_2.bias',
'unet.decoders.11.layers.1.attention_2.q_proj.weight',
'unet.decoders.11.layers.1.attention_2.k_proj.weight',
'unet.decoders.11.layers.1.attention_2.v_proj.weight',
'unet.decoders.11.layers.1.attention_2.out_proj.weight',
'unet.decoders.11.layers.1.attention_2.out_proj.bias',
'unet.decoders.11.layers.1.layernorm_1.weight',
'unet.decoders.11.layers.1.layernorm_1.bias',
'unet.decoders.11.layers.1.layernorm_2.weight',
'unet.decoders.11.layers.1.layernorm_2.bias',
'unet.decoders.11.layers.1.layernorm_3.weight',
'unet.decoders.11.layers.1.layernorm_3.bias',
'unet.decoders.11.layers.1.conv_output.weight',
'unet.decoders.11.layers.1.conv_output.bias',
'final.groupnorm.weight',
'final.groupnorm.bias',
'final.conv.weight',
'final.conv.bias',
'unet.encoders.1.layers.1.attention_1.in_proj.weight',
'unet.encoders.2.layers.1.attention_1.in_proj.weight',
'unet.encoders.4.layers.1.attention_1.in_proj.weight',
'unet.encoders.5.layers.1.attention_1.in_proj.weight',
'unet.encoders.7.layers.1.attention_1.in_proj.weight',
'unet.encoders.8.layers.1.attention_1.in_proj.weight',
'unet.bottleneck.layers.1.attention_1.in_proj.weight',
'unet.decoders.3.layers.1.attention_1.in_proj.weight',
'unet.decoders.4.layers.1.attention_1.in_proj.weight',
'unet.decoders.5.layers.1.attention_1.in_proj.weight',
'unet.decoders.6.layers.1.attention_1.in_proj.weight',
'unet.decoders.7.layers.1.attention_1.in_proj.weight',
'unet.decoders.8.layers.1.attention_1.in_proj.weight',
'unet.decoders.9.layers.1.attention_1.in_proj.weight',
'unet.decoders.10.layers.1.attention_1.in_proj.weight',
'unet.decoders.11.layers.1.attention_1.in_proj.weight'
]